This article details a developer's exploration into the creative capabilities of Large Language Models (LLMs), specifically in generating short science-fiction stories. The author initially built an AI agent using LangChain4j, Gemini for narrative generation, and Imagen for illustrations. While the early results were fascinating, demonstrating the model's ability to craft narratives, describe futuristic settings, and create characters, a significant and recurring pattern soon emerged.

The generated stories frequently featured the same character names, such as "Dr. Thorne" (appearing sometimes as a scientist, other times as a starship captain) and heroines consistently named "Anya" or "Elena." Additionally, planetary names often echoed each other, albeit inspired by current exoplanet findings. This led to a perceived lack of originality and variety in the AI's output.

Initially, the author considered this a limitation of the specific model used, Google's Gemini, questioning its inherent creativity. However, this perspective shifted dramatically upon discovering EQ Bench’s long-form creative writing benchmark. To his surprise, other LLMs from different providers—including Gemini 2.5 Pro, DeepSeek, and Claude Opus 4—also generated sci-fi stories featuring strikingly similar character names. For instance, Gemini 2.5 Pro's sample featured "Dr Aris Thorne," DeepSeek's novel had "Elara Voss," and Claude Opus 4's sample mentioned "Elana Vasquez." This crucial discovery indicated that the issue was not an isolated model quirk but a "systemic" problem observed across various LLMs.

This revelation led to a new hypothesis: the issue wasn't a lack of creativity inherent in the models, but rather a reflection of the data they were trained on. The author posited that for a specialized genre like science fiction, the available training data might be more limited and less diverse than generally assumed. If multiple models were learning from a similar, relatively confined pool of sci-fi literature, it would naturally lead them to reproduce the most common elements, characters, and tropes found within that pool.

To test this hypothesis, the author embarked on a search for science-fiction datasets on Kaggle. His intuition was that large models often train on common datasets of novels, and for niche topics, the specific data within these might be scarce, leading to less diversity. He identified two relevant datasets: the "Science Fiction Books dataset" (featuring metadata for 10,000 books, including descriptions of main characters and narratives) and the "SciFi Stories Text corpus" (a ~150MB text file containing various sci-fi stories).

Using the Gemini CLI, the author then queried these datasets for the repetitive names he had encountered in his generated stories. The results provided compelling evidence: "Dr. Thorne" appeared 204 times across 26 book descriptions, and "Anya" featured 204 times in 8 descriptions within the datasets. Other names like "Althea" and "Elena" were also found to be highly frequent. This confirmed that these names were indeed "very well known" and prevalent within common sci-fi literature corpuses.

The author concluded that the models were not failing creatively; rather, they were succeeding, perhaps too well, at identifying and reproducing the most statistically common patterns present in their training data. The perceived lack of creativity was, in fact, a direct consequence of the limitations and homogeneity of the training data for this specific genre.

The experience offers a crucial nuance in understanding AI and creativity. The article argues that LLMs' creative output is essentially a mirror reflecting the data they have ingested. For broad topics where training data is vast and diverse (e.g., the entire internet), this mirror is so large and multifaceted that the reflections appear endlessly unique. However, for more niche domains like specific subgenres of science fiction, the mirror is smaller, leading to more focused, repetitive reflections where patterns become obvious.

The article emphasizes that LLMs' creativity is not one of imagination in the human sense, but rather a sophisticated form of pattern recognition and recombination. When the underlying patterns in the training data are limited, so too is the apparent creativity of the AI. This doesn't diminish their power as tools but highlights the "critical role of data diversity." For AI to be a truly powerful creative partner in specialized fields, it requires a rich and varied diet of domain-specific information.

Finally, the author outlines plans to improve his story generator by explicitly focusing on creating more diverse character names first, independent of the science-fiction focus (to avoid the pit of common names), then building their profiles, and only then injecting them into the context of the sci-fi world. Until these improvements are implemented, the article humorously concludes, readers may have to grow accustomed to more tales featuring Dr. Thorne and his galactic adventures.
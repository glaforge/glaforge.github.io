In a recent article, the author expressed concerns regarding Google App Engine's (GAE) new pricing policy, particularly given their development work on Gaelyk and deployment of several applications on the platform. This follow-up article details their experience with the new policy and the optimizations undertaken to keep their applications running for free.

The author has nearly ten applications deployed on Google App Engine, though most are inactive demos. Three applications, however, are critical: the Gaelyk website, their personal blog, and the Groovy Web Console. The primary aspects of the new pricing policy that caused worry were "instance hours" and "datastore reads," which historically were the limits the author tended to hit.

For the **Gaelyk website**, the policy changes had no significant impact. This site is primarily static, despite using templates for dynamic page generation. Its pages are extensively cached via the `routes.groovy` configuration, and it performs virtually no datastore access, only minimal reads for memcache access. Consequently, it remained well within its free quotas.

The author's **blog** presented a challenge with frontend instance hours, although datastore reads were just below the limit. The solution involved adjusting GAE's configuration: "moving the max idle instance knobs and latency knobs to their opposite." This tweak significantly reduced the number of instances GAE would spin up for the blog. As a result, even though the website operates 24/7, it now consistently stays under the 28-hour instance limit, resolving the previous issue.

The **Groovy Web Console** proved to be the biggest problem.
Regarding **frontend instance hours**, the application constantly approached the limit. Similar to the blog, adjusting the "knobs to the opposite" helped, though the margin remained tight. However, the author notes a positive aspect of the new policy for this particular application: the shift from CPU consumption to instance hours was beneficial because the console allows users to execute potentially long-running scripts (up to 60 seconds). Under the old CPU-based billing, such usage might have quickly incurred costs.

The most painful aspect for the Groovy Web Console was **datastore reads**. The primary cause was extensive activity from Google Search bots and similar crawlers, which generated a massive number of reads while indexing published Groovy scripts. The author admitted that the application was "not very well written" in this regard. For instance, to display lists of recent scripts, scripts by authors, or scripts by tags, the application performed three distinct but essentially similar queries. Each query typically resulted in 5 read operations (one for the query itself plus two for each indexed column used for sorting/filtering). This meant approximately 15 read operations just to build a single page showing recent scripts. While page caching was in place using memcache (consuming just one read operation), pages frequently fell out of the cache, necessitating these expensive 15-operation datastore fetches.

To address this, the author implemented significant optimizations:
1.  **Query Consolidation:** Instead of executing three separate queries, they refactored the application to perform "just one" query. The subsequent sorting, filtering, and grouping of results were then handled in memory. This optimization immediately reduced the datastore operations from 15 to just 5 per page load.
2.  **Aggressive Memcache Caching:** Going a step further, the results of this consolidated query were then stored in memcache. This meant that most of the time, subsequent requests for the same data would only incur a single read operation from memcache, rather than 5 datastore operations.

These optimizations led to a dramatic reduction in datastore reads, by a factor of approximately 15. The author's monitoring showed that after these changes, the Groovy Web Console consumed only about 40% of its datastore read operations quota by the end of the day, while frontend instance hours remained just under the 28-hour limit.

In conclusion, the author expressed satisfaction that all their significant applications remained free thanks to a combination of Google's post-complaint adjustments to the pricing policy and their own proactive application optimizations. The article ends by inviting other GAE users to share their experiences with the new pricing model and any solutions they found for optimizing their applications.
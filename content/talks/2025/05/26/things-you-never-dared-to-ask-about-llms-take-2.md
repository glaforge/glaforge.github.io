---
title: "Things you never dared to ask about LLMs â€” Take 2"
date: 2025-05-26T12:26:41+02:00
type: "talk"
layout: "talk"
tags:
  - generative-ai
  - large-language-models
---

Recently, I had the chance to deliver this talk on the mysteries of LLMs, at [Devoxx France](https://www.devoxx.fr/agenda-2025/talk/sous-le-capot-des-llms-toutes-ces-questions-que-vous-n-avez-jamais-ose-poser/), with my good friend [Didier Girard](https://www.linkedin.com/in/DidierGirard/),
It was fun to uncover the oddities of LLMs, and better understand where they thrive or fail, and why.

In this post, I'd like to share an update of the presentation deck, with a few additional slides here and there, to cover for example

- the difficulty of LLMs to work with acronyms, scientific molecule names, plant names, special uncommon vocabulary, which require more tokens and weakens _attention_,
- the difference between deterministic and probabilistic problems, and why predictive models are still important,
- some limits of LLMs with regards to understanding dates, data ownership, or the fact they can't easily forget what they learned.

{{< speakerdeck 1d3eae3a34d846888f7183bed5f0597e >}}

This was fun delivering the talk with Didier, as a friendly dialogue makes things more entertaining!
We were lucky that this talk was recorded (however, in French :fr:) and you can watch the [video](https://www.youtube.com/watch?v=C6tZE5OgqUc) below:

{{< youtube C6tZE5OgqUc >}}

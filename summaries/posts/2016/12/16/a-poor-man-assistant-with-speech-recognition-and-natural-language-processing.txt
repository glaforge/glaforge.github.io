This article details the creation of a basic, voice-powered conference assistant using Google's Cloud Speech API and Cloud Natural Language API, primarily implemented through a shell script and various command-line tools. The author, who developed this demo for a Devoxx 2016 keynote on Machine Learning, aimed to illustrate the practical steps involved in building such intelligent assistants.

The core idea behind the "conference assistant" is to allow users to ask questions about topics they wish to find in the conference schedule. For instance, a user might ask, "Is there a talk about the Google Cloud Vision API?". This voice request initiates a multi-step process:
1.  **Voice-to-Text Conversion:** The user's spoken question is sent to the Google Cloud Speech API, which transcribes it into text.
2.  **Text Analysis:** The transcribed text is then processed by the Google Cloud Natural Language API to extract the relevant topic or keywords from the question.
3.  **Schedule Query:** Finally, these extracted keywords are used to query the conference schedule, identifying talks that match the user's interest.

The implementation is notable for its reliance on command-line utilities for all "glue" logic, making it a "fun" and illustrative example of leveraging powerful cloud APIs with traditional scripting. The detailed workflow involves the following steps:

1.  **Audio Recording:** The process begins with recording the user's voice query. This is achieved using the `sox` command-line tool, which captures the audio and saves it locally as a FLAC file (e.g., `query.flac`).
2.  **Cloud Storage Upload:** The recorded audio file (`query.flac`) is then uploaded to Google Cloud Storage (GCS) using the `gsutil copy` command. This makes the audio accessible to the Google Cloud Speech API.
3.  **Speech-to-Text API Call:** A `curl` command is used to make a POST request to the Google Cloud Speech API (`speech.googleapis.com`). This request includes a JSON payload (`speech-request.json`) specifying the audio encoding (FLAC), sample rate (16000 Hz), language (en-US), and the GCS URI of the uploaded audio file. The API returns a JSON response containing the transcribed text, which is saved to `speech-output.json`.
4.  **Transcript Extraction:** The `jq` command-line JSON processor is then used to parse `speech-output.json` and extract the plain text transcript, specifically from `results[0].alternatives[0].transcript`, saving it to `text.txt`.
5.  **Natural Language API Request Preparation:** The extracted transcript (`text.txt`) is incorporated into a JSON template (`nl-request-template.json`) for the Natural Language API. A `sed` command replaces a placeholder (`@TEXT@`) with the actual transcript. The request configures the API to extract syntax (`extractSyntax: true`) from the plain text document, while disabling entity and sentiment extraction for this specific use case. The prepared request is saved as `nl-request.json`.
6.  **Natural Language API Call:** Another `curl` command sends a POST request to the Google Natural Language API (`language.googleapis.com`) with the `nl-request.json` payload. The API's response, containing linguistic analysis, is saved to `nl-output.json`.
7.  **Keyword Extraction from NL Output:**
    *   `jq` is again employed to extract all "lemmas" (base forms of words) from the `nl-output.json` file's `tokens` array, saving them to `lemmas.txt`.
    *   A combination of `sed` and `tail` filters `lemmas.txt` to isolate the words that appear *after* the word "about" in the query, as these are assumed to represent the search topic. These keywords are saved to `keywords.txt`.
    *   Finally, `cat` and `tr` are used to join the keywords from `keywords.txt` into a single string, separated by `+` characters, suitable for a URL query parameter. This is saved to `encoded-keywords.txt`.
8.  **Custom Search Engine Query:** The `encoded-keywords.txt` string is then used to construct a `curl` request to a Google Custom Search Engine (CSE). The CSE is configured to index the conference website's schedule. The `curl` command sends the search query, and `jq` is used one last time to extract and display the `title` of the first search result, which typically corresponds to the most relevant talk.

The article concludes by emphasizing how this solution successfully combines the advanced capabilities of the Google Cloud Speech API for voice recognition, the Natural Language API for text analysis, and a suite of "handy command-line tools" (`sox`, `jq`, `gsutil`, `curl`, `cat`, `sed`, `tr`) to orchestrate the entire process and provide a functional command-line conference assistant. This demonstration effectively showcases the power and flexibility of integrating cloud services with traditional scripting for machine learning applications.